{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:05:31.80266Z","iopub.execute_input":"2025-11-23T13:05:31.802929Z","iopub.status.idle":"2025-11-23T13:05:34.304307Z","shell.execute_reply.started":"2025-11-23T13:05:31.802907Z","shell.execute_reply":"2025-11-23T13:05:34.302972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#As per competitons description, Log RMSE (i.e root mean squared error) to be used instead of RMSE, to judge predicted values.\n#For Ex: if there is a home with actual price 20 crore, whereas there is another home worth 20 lakh, the predicted price lets say for 1st home is 19 crore, and 2nd home is 21 lakh, then the error difference between too is not in the same scale, and costlier house error can dominate the RMSE result.\n#In order to avoid it, we need to bring them to same scale, so we take Log(Predicted Value) and Log(Actual Price) which brings them to same scale, and now we can use these 2 values in RMSE calculation.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T03:07:56.099022Z","iopub.execute_input":"2025-11-22T03:07:56.099324Z","iopub.status.idle":"2025-11-22T03:07:56.128325Z","shell.execute_reply.started":"2025-11-22T03:07:56.099296Z","shell.execute_reply":"2025-11-22T03:07:56.127088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Reading Train.csv data\ntrain_df = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/train.csv\")\ntrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:22:55.148176Z","iopub.execute_input":"2025-11-23T13:22:55.148548Z","iopub.status.idle":"2025-11-23T13:22:55.231448Z","shell.execute_reply.started":"2025-11-23T13:22:55.14852Z","shell.execute_reply":"2025-11-23T13:22:55.230449Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"#lets see features info\ntrain_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:22:59.342817Z","iopub.execute_input":"2025-11-23T13:22:59.343141Z","iopub.status.idle":"2025-11-23T13:22:59.375615Z","shell.execute_reply.started":"2025-11-23T13:22:59.343117Z","shell.execute_reply":"2025-11-23T13:22:59.374654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#lets see how many missing values are there in each feature\ntrain_df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:23:00.500821Z","iopub.execute_input":"2025-11-23T13:23:00.501201Z","iopub.status.idle":"2025-11-23T13:23:00.515451Z","shell.execute_reply.started":"2025-11-23T13:23:00.501172Z","shell.execute_reply":"2025-11-23T13:23:00.514375Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Since there are so many features, by default pd restricts the features to be displayed","metadata":{}},{"cell_type":"code","source":"#Applying a filter to see only the features with missing values\ntrain_df.isnull().sum()[train_df.isnull().sum()>0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:23:05.795396Z","iopub.execute_input":"2025-11-23T13:23:05.795736Z","iopub.status.idle":"2025-11-23T13:23:05.81374Z","shell.execute_reply.started":"2025-11-23T13:23:05.795709Z","shell.execute_reply":"2025-11-23T13:23:05.81276Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#lets see dataset shape\ntrain_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:23:07.116751Z","iopub.execute_input":"2025-11-23T13:23:07.117085Z","iopub.status.idle":"2025-11-23T13:23:07.124684Z","shell.execute_reply.started":"2025-11-23T13:23:07.11706Z","shell.execute_reply":"2025-11-23T13:23:07.123495Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#lets seperate numerical and categorical features\ncategorical = []\nnumerical = []\nfor feature in train_df.columns:\n    if train_df[feature].dtype == 'int64':\n        numerical.append(feature)\n    else:\n        categorical.append(feature)\nprint(\"Categorical : \",categorical)\nprint(\"Numerical : \",numerical)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:23:09.371787Z","iopub.execute_input":"2025-11-23T13:23:09.372112Z","iopub.status.idle":"2025-11-23T13:23:09.379684Z","shell.execute_reply.started":"2025-11-23T13:23:09.372083Z","shell.execute_reply":"2025-11-23T13:23:09.378245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(numerical))\nprint(len(categorical))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:23:10.364755Z","iopub.execute_input":"2025-11-23T13:23:10.36509Z","iopub.status.idle":"2025-11-23T13:23:10.370569Z","shell.execute_reply.started":"2025-11-23T13:23:10.365063Z","shell.execute_reply":"2025-11-23T13:23:10.369253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#lets visualize the target feature i.e SalePrice, to see if we have normal or skewed data or do we have any outliers.\n#using histogram to see the distribution of each price, i.e it shows the count\n#where x is the unique sorted prices\n#y is the occurence of each of those prices.\nimport matplotlib.pyplot as plt\nplt.hist(train_df['SalePrice'])\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:23:11.93955Z","iopub.execute_input":"2025-11-23T13:23:11.940294Z","iopub.status.idle":"2025-11-23T13:23:12.206839Z","shell.execute_reply.started":"2025-11-23T13:23:11.94026Z","shell.execute_reply":"2025-11-23T13:23:12.205325Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"1. Its not a bell curve.\n2. The centre where the peak is between 100000 and 200000, but it should have been near 300000 and 400000.\n3. Does not looks symmetric.\n4. Peak is more towards left side,and tail is towards right,so its right skewed.\n\n### SalePrice is right skewed, and needs to be normalized.","metadata":{}},{"cell_type":"code","source":"#lets see the outliers, using IQR i.e interquartile range\n#since IQR is used for skewed data, while Z-score is for gaussian i.e normal data\n\n#IQR = Q3 - Q1\n#lower bound = Q1 - 1.5* IQR\n#upper bound = Q3 + 1.5* IQR\n\n#we can see this using boxplot\nimport seaborn as sns\nsns.boxplot(train_df['SalePrice'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:23:14.899654Z","iopub.execute_input":"2025-11-23T13:23:14.900048Z","iopub.status.idle":"2025-11-23T13:23:16.164255Z","shell.execute_reply.started":"2025-11-23T13:23:14.90002Z","shell.execute_reply":"2025-11-23T13:23:16.162815Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Prices somewhere from above of 300000 are outliers.","metadata":{}},{"cell_type":"code","source":"#lets see the actual outliers\nQ1 = train_df['SalePrice'].quantile(0.25)\nQ3 = train_df['SalePrice'].quantile(0.75)\nIQR = Q3 - Q1\nlowerBound = Q1 - 1.5*IQR\nupperBound = Q3 + 1.5*IQR\n\noutliers = train_df[(train_df['SalePrice'] > upperBound) | (train_df['SalePrice'] < lowerBound)]\noutliers.shape[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:23:18.814991Z","iopub.execute_input":"2025-11-23T13:23:18.815536Z","iopub.status.idle":"2025-11-23T13:23:18.828559Z","shell.execute_reply.started":"2025-11-23T13:23:18.815511Z","shell.execute_reply":"2025-11-23T13:23:18.827792Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"61 records are outliers here, since these are expensive houses, and not errors, we cant remove them, we will perform feature transformation using log, and similarly on all input features as well.","metadata":{}},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"#handling numerical feature missing values\nfor feature in numerical:\n    print(train_df[feature].isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:23:29.81704Z","iopub.execute_input":"2025-11-23T13:23:29.817386Z","iopub.status.idle":"2025-11-23T13:23:29.828368Z","shell.execute_reply.started":"2025-11-23T13:23:29.817361Z","shell.execute_reply":"2025-11-23T13:23:29.82732Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"None of the numerical features have any missing values.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#handling categorical features missing values\ncolumns_to_be_dropped = []\ncolumns_missing_to_be_replaced_with_mode = []\nfor feature in categorical:\n    if train_df[feature].isnull().sum() > 0:\n        #if missing values are more than 60%, then we need to drop those columns\n        if train_df[feature].isnull().mean() > 0.6:\n            columns_to_be_dropped.append(feature)\n        else:\n            #need to replace the missing values with their mode\n            columns_missing_to_be_replaced_with_mode.append(feature)\nprint(columns_to_be_dropped)\nprint(columns_missing_to_be_replaced_with_mode)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:23:34.578962Z","iopub.execute_input":"2025-11-23T13:23:34.57935Z","iopub.status.idle":"2025-11-23T13:23:34.601684Z","shell.execute_reply.started":"2025-11-23T13:23:34.579325Z","shell.execute_reply":"2025-11-23T13:23:34.60055Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#droppping columns\ntrain_df.drop(columns = columns_to_be_dropped, inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:23:42.235512Z","iopub.execute_input":"2025-11-23T13:23:42.235866Z","iopub.status.idle":"2025-11-23T13:23:42.243101Z","shell.execute_reply.started":"2025-11-23T13:23:42.235832Z","shell.execute_reply":"2025-11-23T13:23:42.242045Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#replacing the missing values with their mode\nfor feature in columns_missing_to_be_replaced_with_mode:\n    train_df[feature].fillna(train_df[feature].mode()[0], inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:23:43.283369Z","iopub.execute_input":"2025-11-23T13:23:43.28365Z","iopub.status.idle":"2025-11-23T13:23:43.306455Z","shell.execute_reply.started":"2025-11-23T13:23:43.28363Z","shell.execute_reply":"2025-11-23T13:23:43.305418Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.isnull().sum()[train_df.isnull().sum() > 0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:23:46.6534Z","iopub.execute_input":"2025-11-23T13:23:46.653776Z","iopub.status.idle":"2025-11-23T13:23:46.670106Z","shell.execute_reply.started":"2025-11-23T13:23:46.653741Z","shell.execute_reply":"2025-11-23T13:23:46.668559Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Numerical features did not have any missing values.\nCategorical features with more than 60% percent missing values has been dropped, and rest has been filled with their mode value i.e most occurent value.","metadata":{}},{"cell_type":"code","source":"#Encoding\n#1. Label Encoding - where each unique value in the feature itself is converted to 0,1,2...(mostly used for preserving the order)\n#2. One Hot Encoding - creates new column for each value in the feature, and values are populated with 0 and 1.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:23:49.516655Z","iopub.execute_input":"2025-11-23T13:23:49.516989Z","iopub.status.idle":"2025-11-23T13:23:49.521994Z","shell.execute_reply.started":"2025-11-23T13:23:49.516964Z","shell.execute_reply":"2025-11-23T13:23:49.520901Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filtered_categorical_features = list(set(categorical) - set(columns_to_be_dropped))\nfiltered_categorical_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:23:51.21159Z","iopub.execute_input":"2025-11-23T13:23:51.211899Z","iopub.status.idle":"2025-11-23T13:23:51.220607Z","shell.execute_reply.started":"2025-11-23T13:23:51.211877Z","shell.execute_reply":"2025-11-23T13:23:51.219154Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df[filtered_categorical_features].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:23:54.177349Z","iopub.execute_input":"2025-11-23T13:23:54.177736Z","iopub.status.idle":"2025-11-23T13:23:54.202317Z","shell.execute_reply.started":"2025-11-23T13:23:54.17771Z","shell.execute_reply":"2025-11-23T13:23:54.201269Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"If the values of these features requires their order to be preserved, we will use LabelEncoder, else for rest One Hot Encoding.\nManually we need to pick them.","metadata":{}},{"cell_type":"code","source":"for feature in filtered_categorical_features:\n    print(feature, train_df[feature].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:23:56.582326Z","iopub.execute_input":"2025-11-23T13:23:56.583977Z","iopub.status.idle":"2025-11-23T13:23:56.607305Z","shell.execute_reply.started":"2025-11-23T13:23:56.583932Z","shell.execute_reply":"2025-11-23T13:23:56.606237Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['MasVnrArea'] = train_df['MasVnrArea'].astype(float)\ntrain_df['MasVnrArea']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:23:57.02209Z","iopub.execute_input":"2025-11-23T13:23:57.022418Z","iopub.status.idle":"2025-11-23T13:23:57.031739Z","shell.execute_reply.started":"2025-11-23T13:23:57.022393Z","shell.execute_reply":"2025-11-23T13:23:57.030448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df[['LotFrontage','GarageYrBlt']] = train_df[['LotFrontage','GarageYrBlt']].astype(int)\ntrain_df[['LotFrontage','GarageYrBlt']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:24:01.859609Z","iopub.execute_input":"2025-11-23T13:24:01.860141Z","iopub.status.idle":"2025-11-23T13:24:01.872762Z","shell.execute_reply.started":"2025-11-23T13:24:01.860109Z","shell.execute_reply":"2025-11-23T13:24:01.871918Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Ordinal mapping for \n\n#KitchenQual ['Gd' 'TA' 'Ex' 'Fa']\n#HeatingQC ['Ex' 'Gd' 'TA' 'Fa' 'Po']\n#GarageQual ['TA' 'Fa' 'Gd' 'Ex' 'Po']\n#GarageCond ['TA' 'Fa' 'Gd' 'Po' 'Ex']\n#BsmtQual ['Gd' 'TA' 'Ex' 'Fa']\n#FireplaceQu ['Gd' 'TA' 'Fa' 'Ex' 'Po']\n#ExterQual ['Gd' 'TA' 'Ex' 'Fa']\n#BsmtCond ['TA' 'Gd' 'Fa' 'Po']\n#ExterCond ['TA' 'Gd' 'Fa' 'Po' 'Ex']\n\n#LotShape ['Reg' 'IR1' 'IR2' 'IR3']\n#BsmtExposure ['No' 'Gd' 'Mn' 'Av']\n#PavedDrive ['Y' 'N' 'P']\n#BsmtFinType1 ['GLQ' 'ALQ' 'Unf' 'Rec' 'BLQ' 'LwQ']\n#GarageFinish ['RFn' 'Unf' 'Fin']\n#LandSlope ['Gtl' 'Mod' 'Sev']\n#BsmtFinType2 ['Unf' 'BLQ' 'ALQ' 'Rec' 'LwQ' 'GLQ']\n#Functional ['Typ' 'Min1' 'Maj1' 'Min2' 'Mod' 'Maj2' 'Sev']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:24:04.321278Z","iopub.execute_input":"2025-11-23T13:24:04.321581Z","iopub.status.idle":"2025-11-23T13:24:04.326801Z","shell.execute_reply.started":"2025-11-23T13:24:04.321558Z","shell.execute_reply":"2025-11-23T13:24:04.325671Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"quality_map = {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\nquality_features = ['KitchenQual','HeatingQC', 'GarageQual','GarageCond','BsmtQual','FireplaceQu','BsmtCond','ExterCond','ExterQual']\nfor feature in quality_features:\n    train_df[feature] = train_df[feature].map(quality_map)\ntrain_df[quality_features]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:24:05.024658Z","iopub.execute_input":"2025-11-23T13:24:05.025234Z","iopub.status.idle":"2025-11-23T13:24:05.051977Z","shell.execute_reply.started":"2025-11-23T13:24:05.0252Z","shell.execute_reply":"2025-11-23T13:24:05.050715Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"LotShape_map  = {'Reg':3 ,'IR1':2, 'IR2':1, 'IR3':0}\nBsmtExposure_map = {'No':0, 'Gd':3, 'Mn':1 ,'Av':2}\nPavedDrive_map  = {'Y':2, 'N':0, 'P':1}\nBsmtFinType1_map  = {'GLQ':5, 'ALQ':2, 'Unf':0, 'Rec':3, 'BLQ':4, 'LwQ':1}\nBsmtFinType2_map  = {'GLQ':5, 'ALQ':2, 'Unf':0, 'Rec':3, 'BLQ':4, 'LwQ':1}\nGarageFinish_map =  {'RFn':1, 'Unf':0 ,'Fin':2}\nLandSlope_map =  {'Gtl':2, 'Mod':1, 'Sev':0}\nFunctional_map = {'Sev': 1,'Maj2': 2, 'Maj1': 3, 'Mod': 4, 'Min2': 5, 'Min1': 6, 'Typ': 7}\nadditional_ordinal_features = ['LotShape','BsmtExposure','PavedDrive','BsmtFinType1','BsmtFinType2','GarageFinish','LandSlope','Functional']\n\n# Dictionary of all maps\nall_maps = {\n    'LotShape': LotShape_map,\n    'BsmtExposure': BsmtExposure_map,\n    'PavedDrive': PavedDrive_map,\n    'BsmtFinType1': BsmtFinType1_map,\n    'BsmtFinType2': BsmtFinType2_map,\n    'GarageFinish': GarageFinish_map,\n    'LandSlope': LandSlope_map,\n    'Functional': Functional_map\n}\n\nfor feature in additional_ordinal_features:\n    train_df[feature] = train_df[feature].map(all_maps[feature])\ntrain_df[additional_ordinal_features]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:24:07.162344Z","iopub.execute_input":"2025-11-23T13:24:07.162664Z","iopub.status.idle":"2025-11-23T13:24:07.191032Z","shell.execute_reply.started":"2025-11-23T13:24:07.16264Z","shell.execute_reply":"2025-11-23T13:24:07.189868Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categorical_left = list(set(filtered_categorical_features) - set(['GarageYrBlt','LotFrontage','MasVnrArea']) - set(additional_ordinal_features) - set(quality_features))\ncategorical_left","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:24:09.762021Z","iopub.execute_input":"2025-11-23T13:24:09.762442Z","iopub.status.idle":"2025-11-23T13:24:09.769872Z","shell.execute_reply.started":"2025-11-23T13:24:09.762415Z","shell.execute_reply":"2025-11-23T13:24:09.768773Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for feature in categorical_left:\n    print(feature, train_df[feature].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:24:12.167072Z","iopub.execute_input":"2025-11-23T13:24:12.167764Z","iopub.status.idle":"2025-11-23T13:24:12.18034Z","shell.execute_reply.started":"2025-11-23T13:24:12.167729Z","shell.execute_reply":"2025-11-23T13:24:12.178832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#lets drop the features which is not required Ex: Id\ntrain_df.drop(columns = ['Id'], inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:24:14.478165Z","iopub.execute_input":"2025-11-23T13:24:14.47919Z","iopub.status.idle":"2025-11-23T13:24:14.486628Z","shell.execute_reply.started":"2025-11-23T13:24:14.479127Z","shell.execute_reply":"2025-11-23T13:24:14.485444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#lets drop features where almost 95% values are same\n#value_counts gives highest to lowest count\n#normalize = True gives us the percentage directly\n#we can pick the first value and check\nlow_variance_features = [] #data is almost same\nfor feature in train_df.columns:\n    if train_df[feature].value_counts(normalize = True).iloc[0] >= 0.95:\n        low_variance_features.append(feature)\nlow_variance_features","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:24:17.892241Z","iopub.execute_input":"2025-11-23T13:24:17.892572Z","iopub.status.idle":"2025-11-23T13:24:17.941102Z","shell.execute_reply.started":"2025-11-23T13:24:17.892548Z","shell.execute_reply":"2025-11-23T13:24:17.940154Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#drop low_variance_features\ntrain_df.drop(columns= low_variance_features, inplace = True)\ntrain_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:24:20.841039Z","iopub.execute_input":"2025-11-23T13:24:20.841358Z","iopub.status.idle":"2025-11-23T13:24:20.851654Z","shell.execute_reply.started":"2025-11-23T13:24:20.841334Z","shell.execute_reply":"2025-11-23T13:24:20.850495Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"categorical_left= list(set(categorical_left)- set(low_variance_features))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:24:21.932277Z","iopub.execute_input":"2025-11-23T13:24:21.932566Z","iopub.status.idle":"2025-11-23T13:24:21.937465Z","shell.execute_reply.started":"2025-11-23T13:24:21.932545Z","shell.execute_reply":"2025-11-23T13:24:21.93644Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#applying OHE on these categorical_left\ndummies = pd.get_dummies(train_df[categorical_left], drop_first = False)\ntrain_df = pd.concat([train_df, dummies], axis=1)\ntrain_df2 = train_df.copy()\ntrain_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:24:22.740006Z","iopub.execute_input":"2025-11-23T13:24:22.741107Z","iopub.status.idle":"2025-11-23T13:24:22.767013Z","shell.execute_reply.started":"2025-11-23T13:24:22.74107Z","shell.execute_reply":"2025-11-23T13:24:22.76609Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#dropping all categorical_left columns\ntrain_df.drop(columns = categorical_left, inplace = True)\ntrain_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:24:24.979354Z","iopub.execute_input":"2025-11-23T13:24:24.979672Z","iopub.status.idle":"2025-11-23T13:24:24.990376Z","shell.execute_reply.started":"2025-11-23T13:24:24.979647Z","shell.execute_reply":"2025-11-23T13:24:24.989301Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Label Encoding ends here..","metadata":{}},{"cell_type":"code","source":"#using YearBuilt , GarageYrBlt , YrSold ,MoSold, YearRemodAdd\n#MoSold is month, no need to drop them as they tell which month , season has high/low price.\ntrain_df['HouseAge'] = train_df['YrSold'] - train_df['YearBuilt']\ntrain_df['GarageAge'] = train_df['YrSold'] - train_df['GarageYrBlt']\ntrain_df['RemodAdd'] = train_df['YrSold'] - train_df['YearRemodAdd']\ntrain_df.drop(columns = ['YrSold','YearBuilt','GarageYrBlt','YearRemodAdd'], inplace = True)\n#clipping negative values to 0\ntrain_df[\"RemodAdd\"] = train_df[\"RemodAdd\"].clip(lower=0)\ntrain_df[['HouseAge','GarageAge','RemodAdd']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:24:28.632167Z","iopub.execute_input":"2025-11-23T13:24:28.632564Z","iopub.status.idle":"2025-11-23T13:24:28.655938Z","shell.execute_reply.started":"2025-11-23T13:24:28.63254Z","shell.execute_reply":"2025-11-23T13:24:28.654447Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['RemodAdd'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:24:30.665941Z","iopub.execute_input":"2025-11-23T13:24:30.666314Z","iopub.status.idle":"2025-11-23T13:24:30.675197Z","shell.execute_reply.started":"2025-11-23T13:24:30.666287Z","shell.execute_reply":"2025-11-23T13:24:30.67413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"matrix = train_df.corr()\nmatrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:24:32.804183Z","iopub.execute_input":"2025-11-23T13:24:32.80449Z","iopub.status.idle":"2025-11-23T13:24:32.967261Z","shell.execute_reply.started":"2025-11-23T13:24:32.804467Z","shell.execute_reply":"2025-11-23T13:24:32.966096Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#lets keep the threshold as -0.9 and 0.9 for similarity between 2 features,\n#if its there, we will just keep one of the feature.\ncols_n = len(train_df.columns)\nrows_n = cols_n\nsimilar_feats = []\nfor i in range(rows_n):\n    for j in range(i+1,cols_n):\n        #for correlation values less than 0.9 and greater than 0.9    \n        if abs(matrix.iloc[i,j]) > 0.9:\n                similar_feats.append(train_df.columns[i])\nsimilar_feats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:27:05.230874Z","iopub.execute_input":"2025-11-23T13:27:05.23127Z","iopub.status.idle":"2025-11-23T13:27:05.550858Z","shell.execute_reply.started":"2025-11-23T13:27:05.231242Z","shell.execute_reply":"2025-11-23T13:27:05.549896Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#dropping similar features\ntrain_df.drop(columns = similar_feats, inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:28:19.430648Z","iopub.execute_input":"2025-11-23T13:28:19.431791Z","iopub.status.idle":"2025-11-23T13:28:19.438527Z","shell.execute_reply.started":"2025-11-23T13:28:19.431748Z","shell.execute_reply":"2025-11-23T13:28:19.437394Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"we dont have any such features with 90% similarity","metadata":{}},{"cell_type":"code","source":"#Normalization(to remove skewness of data)\n#log(0) is undefined, in order to avoid it we use np.1p(feature) which is log(1+x)\n\n#check skewness first, if more than 0.5 then apply log transformation.\n#we just need to check it on numerical features.\nnumerical_present = list(set(numerical) - set(['Id', 'YearBuilt', 'YearRemodAdd', 'LowQualFinSF', 'KitchenAbvGr', '3SsnPorch', 'PoolArea', 'MiscVal', 'YrSold']))\nnumerical_present = list(set(numerical_present).union({'HouseAge','GarageAge','RemodAdd'}))\nfeatures_requiring_normalization = train_df[numerical_present].skew()[train_df[numerical_present].skew() > 0.5].index\nfeatures_requiring_normalization","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:28:24.140682Z","iopub.execute_input":"2025-11-23T13:28:24.141721Z","iopub.status.idle":"2025-11-23T13:28:24.166981Z","shell.execute_reply.started":"2025-11-23T13:28:24.141673Z","shell.execute_reply":"2025-11-23T13:28:24.165993Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#lets visualize the skewness for features_requiring_normalization\nimport math\nimport matplotlib.pyplot as plt\n\nn = len(features_requiring_normalization)\nrows = math.ceil(math.sqrt(n))\ncols = math.ceil(n / rows)\n\nfig, axes = plt.subplots(rows, cols, figsize=(20, 20))\naxes = axes.flatten()\n\nfor i, col in enumerate(features_requiring_normalization):\n    axes[i].hist(train_df[col])\n    axes[i].set_title(col)\n\n# Hide unused axes\nfor j in range(i + 1, len(axes)):\n    axes[j].set_visible(False)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:28:37.191834Z","iopub.execute_input":"2025-11-23T13:28:37.192271Z","iopub.status.idle":"2025-11-23T13:28:41.529196Z","shell.execute_reply.started":"2025-11-23T13:28:37.192248Z","shell.execute_reply":"2025-11-23T13:28:41.527732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df[features_requiring_normalization] = np.log1p(train_df[features_requiring_normalization])\ntrain_df[features_requiring_normalization]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:28:46.370557Z","iopub.execute_input":"2025-11-23T13:28:46.371519Z","iopub.status.idle":"2025-11-23T13:28:46.412815Z","shell.execute_reply.started":"2025-11-23T13:28:46.371486Z","shell.execute_reply":"2025-11-23T13:28:46.411784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features_requiring_scaling = list(set(features_requiring_normalization) - set(['SalePrice']))\nfeatures_requiring_scaling","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:28:51.230597Z","iopub.execute_input":"2025-11-23T13:28:51.231043Z","iopub.status.idle":"2025-11-23T13:28:51.23873Z","shell.execute_reply.started":"2025-11-23T13:28:51.231012Z","shell.execute_reply":"2025-11-23T13:28:51.237843Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#now we need to scale and bring all the values to same scale, so any high value does not dominates the rest of the values.\nfrom sklearn.preprocessing import StandardScaler #since data is normalized already, else would have used MinMaxScaler\nsc = StandardScaler()\n\n#scaling is not applied on target feature and neither on categorical, since it alters the only thing we want to predict as it is.\ntrain_df[features_requiring_scaling] = sc.fit_transform(train_df[features_requiring_scaling])\ntrain_df[features_requiring_scaling]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:28:55.34616Z","iopub.execute_input":"2025-11-23T13:28:55.346489Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Model Building","metadata":{}},{"cell_type":"code","source":"Y = train_df['SalePrice']\nX = train_df.drop(columns = ['SalePrice'])\nprint(X.shape, Y.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 32)\nprint(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:31:19.166354Z","iopub.execute_input":"2025-11-23T13:31:19.166713Z","iopub.status.idle":"2025-11-23T13:31:19.358065Z","shell.execute_reply.started":"2025-11-23T13:31:19.166664Z","shell.execute_reply":"2025-11-23T13:31:19.357082Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#LinearRegression Model\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nmodel = LinearRegression()\nmodel.fit(x_train, y_train)\n\ny_predicted = model.predict(x_train)\ny_test_predicted = model.predict(x_test)\n\n#squared = False, means RMSE.\nprint(\"Train RMSE: \", mean_squared_error(y_train, y_predicted,squared = False))\nprint(\"Test RMSE: \", mean_squared_error(y_test_predicted, y_test,squared = False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:31:22.891601Z","iopub.execute_input":"2025-11-23T13:31:22.892341Z","iopub.status.idle":"2025-11-23T13:31:23.093957Z","shell.execute_reply.started":"2025-11-23T13:31:22.89231Z","shell.execute_reply":"2025-11-23T13:31:23.09159Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"RMSE lower than 0.15 is actually considered good","metadata":{}},{"cell_type":"code","source":"#Ridge Regression\nfrom sklearn.linear_model import Ridge\n\nfor a in [0.005,0.05,0.1, 0.3, 1, 3, 10, 30, 100]:\n    ridge_model = Ridge(alpha=a)\n    ridge_model.fit(x_train, y_train)\n    \n    y2_predicted = ridge_model.predict(x_train)\n    y2_test_predicted = ridge_model.predict(x_test)\n    \n    #squared = False, means RMSE.\n    print(\"Train RMSE: \", mean_squared_error(y_train, y2_predicted,squared = False))\n    print(\"Test RMSE: \", mean_squared_error(y2_test_predicted, y_test,squared = False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:50:09.013447Z","iopub.execute_input":"2025-11-23T13:50:09.013778Z","iopub.status.idle":"2025-11-23T13:50:09.169493Z","shell.execute_reply.started":"2025-11-23T13:50:09.013753Z","shell.execute_reply":"2025-11-23T13:50:09.16845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Lasso Regression\nfrom sklearn.linear_model import Lasso\n\nfor a in [0.001,0.1, 0.3, 1, 3, 10, 30, 100]:\n    lasso_model = Lasso(alpha=a)\n    lasso_model.fit(x_train, y_train)\n    \n    y3_predicted = lasso_model.predict(x_train)\n    y3_test_predicted = lasso_model.predict(x_test)\n    \n    #squared = False, means RMSE.\n    print(\"Train RMSE: \", mean_squared_error(y_train, y3_predicted,squared = False))\n    print(\"Test RMSE: \", mean_squared_error(y3_test_predicted, y_test,squared = False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:51:07.250857Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#XGBoost Model\nfrom xgboost import XGBRegressor\n\nxgb_model = XGBRegressor(\n    n_estimators=500,\n    learning_rate=0.05,\n    max_depth=3,\n    subsample=0.8,\n    colsample_bytree=0.7,\n    reg_alpha=0.1,\n    reg_lambda=1.0\n)\nxgb_model.fit(x_train, y_train)\n\ny4_predicted = xgb_model.predict(x_train)\ny4_test_predicted = xgb_model.predict(x_test)\n\n#squared = False, means RMSE.\nprint(\"Train RMSE: \", mean_squared_error(y_train, y4_predicted,squared = False))\nprint(\"Test RMSE: \", mean_squared_error(y4_test_predicted, y_test,squared = False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:55:42.86768Z","iopub.execute_input":"2025-11-23T13:55:42.868056Z","iopub.status.idle":"2025-11-23T13:55:43.551197Z","shell.execute_reply.started":"2025-11-23T13:55:42.868029Z","shell.execute_reply":"2025-11-23T13:55:43.549348Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#LightBGM Model\nfrom lightgbm import LGBMRegressor\n\nlgbm = LGBMRegressor(\n    n_estimators=2000,\n    learning_rate=0.05,\n    max_depth=-1,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42\n)\nlgbm.fit(x_train, y_train)\n\ny5_predicted = lgbm.predict(x_train)\ny5_test_predicted = lgbm.predict(x_test)\n\n#squared = False, means RMSE.\nprint(\"Train RMSE: \", mean_squared_error(y_train, y5_predicted,squared = False))\nprint(\"Test RMSE: \", mean_squared_error(y5_test_predicted, y_test,squared = False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:53:51.068446Z","iopub.execute_input":"2025-11-23T13:53:51.068862Z","iopub.status.idle":"2025-11-23T13:53:54.76233Z","shell.execute_reply.started":"2025-11-23T13:53:51.068831Z","shell.execute_reply":"2025-11-23T13:53:54.761416Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#GradientBoost Model\nfrom sklearn.ensemble import GradientBoostingRegressor\n\ngbr = GradientBoostingRegressor(\n    n_estimators=3000,\n    learning_rate=0.05,\n    max_depth=4,\n    random_state=42\n)\ngbr.fit(x_train, y_train)\n\ny6_predicted = gbr.predict(x_train)\ny6_test_predicted = gbr.predict(x_test)\n\n#squared = False, means RMSE.\nprint(\"Train RMSE: \", mean_squared_error(y_train, y6_predicted,squared = False))\nprint(\"Test RMSE: \", mean_squared_error(y6_test_predicted, y_test,squared = False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:38:24.926109Z","iopub.execute_input":"2025-11-23T13:38:24.926428Z","iopub.status.idle":"2025-11-23T13:38:56.595328Z","shell.execute_reply.started":"2025-11-23T13:38:24.926405Z","shell.execute_reply":"2025-11-23T13:38:56.594258Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#SVM Model\nfrom sklearn.svm import SVR\n\nsvr = SVR(C=20, epsilon=0.01, kernel='rbf')\nsvr.fit(x_train, y_train)\n\ny7_predicted = svr.predict(x_train)\ny7_test_predicted = svr.predict(x_test)\n\n#squared = False, means RMSE.\nprint(\"Train RMSE: \", mean_squared_error(y_train, y7_predicted,squared = False))\nprint(\"Test RMSE: \", mean_squared_error(y7_test_predicted, y_test,squared = False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:39:17.058425Z","iopub.execute_input":"2025-11-23T13:39:17.058753Z","iopub.status.idle":"2025-11-23T13:39:17.690517Z","shell.execute_reply.started":"2025-11-23T13:39:17.058732Z","shell.execute_reply":"2025-11-23T13:39:17.689326Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#KNN Regressor\nfrom sklearn.neighbors import KNeighborsRegressor\n\nknn = KNeighborsRegressor(n_neighbors=5)\nknn.fit(x_train, y_train)\n\ny8_predicted = knn.predict(x_train)\ny8_test_predicted = knn.predict(x_test)\n\n#squared = False, means RMSE.\nprint(\"Train RMSE: \", mean_squared_error(y_train, y8_predicted,squared = False))\nprint(\"Test RMSE: \", mean_squared_error(y8_test_predicted, y_test,squared = False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T13:39:23.111151Z","iopub.execute_input":"2025-11-23T13:39:23.111449Z","iopub.status.idle":"2025-11-23T13:39:23.194821Z","shell.execute_reply.started":"2025-11-23T13:39:23.111429Z","shell.execute_reply":"2025-11-23T13:39:23.193241Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Ridge has the lowest RMSE on the test data, so picking it.","metadata":{}},{"cell_type":"code","source":"#Ridge Regression(Training it on entire X,Y i.e before split)\nfrom sklearn.linear_model import Ridge\n\nfor a in [0.001,0.05,0.1, 0.3, 1, 3, 10, 30, 100]:\n    ridge_model = Ridge(alpha=a)\n    ridge_model.fit(X, Y)\n    \n    y10_predicted = ridge_model.predict(x_train)\n    y10_test_predicted = ridge_model.predict(x_test)\n    \n    #squared = False, means RMSE.\n    print(\"Train RMSE: \", mean_squared_error(y_train, y10_predicted,squared = False))\n    print(\"Test RMSE: \", mean_squared_error(y10_test_predicted, y_test,squared = False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:02:33.047798Z","iopub.execute_input":"2025-11-23T14:02:33.048131Z","iopub.status.idle":"2025-11-23T14:02:33.267199Z","shell.execute_reply.started":"2025-11-23T14:02:33.048106Z","shell.execute_reply":"2025-11-23T14:02:33.266061Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"0.001 has lowest RMSE here, so picking it","metadata":{}},{"cell_type":"code","source":"ridge_model = Ridge(alpha=0.001)\nridge_model.fit(X, Y)\n\ny10_predicted = ridge_model.predict(x_train)\ny10_test_predicted = ridge_model.predict(x_test)\n\n#squared = False, means RMSE.\nprint(\"Train RMSE: \", mean_squared_error(y_train, y10_predicted,squared = False))\nprint(\"Test RMSE: \", mean_squared_error(y10_test_predicted, y_test,squared = False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:02:42.582492Z","iopub.execute_input":"2025-11-23T14:02:42.582826Z","iopub.status.idle":"2025-11-23T14:02:42.613437Z","shell.execute_reply.started":"2025-11-23T14:02:42.582802Z","shell.execute_reply":"2025-11-23T14:02:42.612472Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Performing the same set of process on test.csv data now\ntest_df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\ntest_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:03:12.78265Z","iopub.execute_input":"2025-11-23T14:03:12.783651Z","iopub.status.idle":"2025-11-23T14:03:12.822211Z","shell.execute_reply.started":"2025-11-23T14:03:12.783622Z","shell.execute_reply":"2025-11-23T14:03:12.821152Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numerical = []\ncategorical = []\n\nfor feature in test_df.columns:\n    if test_df[feature].dtype in ('int64', 'float64'):\n        numerical.append(feature)\n    else:\n        categorical.append(feature)\n\nprint(\"Numerical: \", numerical)\nprint(\"Categorical: \", categorical)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:03:14.92282Z","iopub.execute_input":"2025-11-23T14:03:14.923413Z","iopub.status.idle":"2025-11-23T14:03:14.934674Z","shell.execute_reply.started":"2025-11-23T14:03:14.923378Z","shell.execute_reply":"2025-11-23T14:03:14.933616Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#handling numerical feature missing values\nnumerical = list(set(numerical) - set(['SalePrice']))\nfor feature in numerical:\n    if test_df[feature].isnull().sum() > 0 :\n        test_df[feature].fillna(test_df[feature].mean(), inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:03:17.627331Z","iopub.execute_input":"2025-11-23T14:03:17.627646Z","iopub.status.idle":"2025-11-23T14:03:17.645436Z","shell.execute_reply.started":"2025-11-23T14:03:17.627624Z","shell.execute_reply":"2025-11-23T14:03:17.644243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n#droppping columns\ntest_df.drop(columns = columns_to_be_dropped, inplace = True)\n\n#replacing the missing values with their mode\nfor feature in columns_missing_to_be_replaced_with_mode:\n    test_df[feature].fillna(test_df[feature].mode()[0], inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:03:19.808345Z","iopub.execute_input":"2025-11-23T14:03:19.808651Z","iopub.status.idle":"2025-11-23T14:03:19.831383Z","shell.execute_reply.started":"2025-11-23T14:03:19.808628Z","shell.execute_reply":"2025-11-23T14:03:19.830107Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"additional_missing_cat = []\nfor feature in test_df.columns:\n    if test_df[feature].isnull().sum()[test_df[feature].isnull().sum() > 0]:\n        additional_missing_cat.append(feature)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:03:22.467984Z","iopub.execute_input":"2025-11-23T14:03:22.468356Z","iopub.status.idle":"2025-11-23T14:03:22.502641Z","shell.execute_reply.started":"2025-11-23T14:03:22.468333Z","shell.execute_reply":"2025-11-23T14:03:22.501508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"additional_missing_cat","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:03:24.902174Z","iopub.execute_input":"2025-11-23T14:03:24.902484Z","iopub.status.idle":"2025-11-23T14:03:24.90847Z","shell.execute_reply.started":"2025-11-23T14:03:24.902465Z","shell.execute_reply":"2025-11-23T14:03:24.907154Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for feature in additional_missing_cat:\n    test_df[feature].fillna(test_df[feature].mode()[0], inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:03:27.052499Z","iopub.execute_input":"2025-11-23T14:03:27.053548Z","iopub.status.idle":"2025-11-23T14:03:27.065172Z","shell.execute_reply.started":"2025-11-23T14:03:27.053517Z","shell.execute_reply":"2025-11-23T14:03:27.064225Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.isnull().sum()[test_df.isnull().sum() > 0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:03:28.350506Z","iopub.execute_input":"2025-11-23T14:03:28.351044Z","iopub.status.idle":"2025-11-23T14:03:28.366724Z","shell.execute_reply.started":"2025-11-23T14:03:28.351012Z","shell.execute_reply":"2025-11-23T14:03:28.365404Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df['MasVnrArea'] = test_df['MasVnrArea'].astype(float)\ntest_df[['LotFrontage','GarageYrBlt']] = test_df[['LotFrontage','GarageYrBlt']].astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:03:30.327322Z","iopub.execute_input":"2025-11-23T14:03:30.327603Z","iopub.status.idle":"2025-11-23T14:03:30.33649Z","shell.execute_reply.started":"2025-11-23T14:03:30.327584Z","shell.execute_reply":"2025-11-23T14:03:30.335274Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"quality_map = {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\nquality_features = ['KitchenQual','HeatingQC', 'GarageQual','GarageCond','BsmtQual','FireplaceQu','BsmtCond','ExterCond','ExterQual']\nfor feature in quality_features:\n    test_df[feature] = test_df[feature].map(quality_map)\ntest_df[quality_features]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:03:31.223406Z","iopub.execute_input":"2025-11-23T14:03:31.223829Z","iopub.status.idle":"2025-11-23T14:03:31.255478Z","shell.execute_reply.started":"2025-11-23T14:03:31.223796Z","shell.execute_reply":"2025-11-23T14:03:31.254387Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"LotShape_map  = {'Reg':3 ,'IR1':2, 'IR2':1, 'IR3':0}\nBsmtExposure_map = {'No':0, 'Gd':3, 'Mn':1 ,'Av':2}\nPavedDrive_map  = {'Y':2, 'N':0, 'P':1}\nBsmtFinType1_map  = {'GLQ':5, 'ALQ':2, 'Unf':0, 'Rec':3, 'BLQ':4, 'LwQ':1}\nBsmtFinType2_map  = {'GLQ':5, 'ALQ':2, 'Unf':0, 'Rec':3, 'BLQ':4, 'LwQ':1}\nGarageFinish_map =  {'RFn':1, 'Unf':0 ,'Fin':2}\nLandSlope_map =  {'Gtl':2, 'Mod':1, 'Sev':0}\nFunctional_map = {'Sev': 1,'Maj2': 2, 'Maj1': 3, 'Mod': 4, 'Min2': 5, 'Min1': 6, 'Typ': 7}\nadditional_ordinal_features = ['LotShape','BsmtExposure','PavedDrive','BsmtFinType1','BsmtFinType2','GarageFinish','LandSlope','Functional']\n\n# Dictionary of all maps\nall_maps = {\n    'LotShape': LotShape_map,\n    'BsmtExposure': BsmtExposure_map,\n    'PavedDrive': PavedDrive_map,\n    'BsmtFinType1': BsmtFinType1_map,\n    'BsmtFinType2': BsmtFinType2_map,\n    'GarageFinish': GarageFinish_map,\n    'LandSlope': LandSlope_map,\n    'Functional': Functional_map\n}\n\nfor feature in additional_ordinal_features:\n    test_df[feature] = test_df[feature].map(all_maps[feature])\ntest_df[additional_ordinal_features]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:03:33.562859Z","iopub.execute_input":"2025-11-23T14:03:33.563272Z","iopub.status.idle":"2025-11-23T14:03:33.592374Z","shell.execute_reply.started":"2025-11-23T14:03:33.563245Z","shell.execute_reply":"2025-11-23T14:03:33.591079Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#drop low_variance_features\ntest_df.drop(columns= low_variance_features, inplace = True)\ntest_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:03:38.622404Z","iopub.execute_input":"2025-11-23T14:03:38.62273Z","iopub.status.idle":"2025-11-23T14:03:38.632987Z","shell.execute_reply.started":"2025-11-23T14:03:38.622688Z","shell.execute_reply":"2025-11-23T14:03:38.631802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#applying OHE on these categorical_left\ndummies = pd.get_dummies(test_df[categorical_left], drop_first = False)\ntest_df = pd.concat([test_df, dummies], axis=1)\ntest_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:03:43.849374Z","iopub.execute_input":"2025-11-23T14:03:43.849719Z","iopub.status.idle":"2025-11-23T14:03:43.877211Z","shell.execute_reply.started":"2025-11-23T14:03:43.849673Z","shell.execute_reply":"2025-11-23T14:03:43.87624Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#due to different values in train.csv and test.csv, pd.get_dummies may generate different number of columns, which is expected\n#so we need to add features from train to test, to align the feature count of test, then only it can be used by the trained model.\nalign_cols = list(set(train_df2) - set(test_df))\nfor col in align_cols:\n    test_df[col] = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:06:07.578816Z","iopub.execute_input":"2025-11-23T14:06:07.579158Z","iopub.status.idle":"2025-11-23T14:06:07.588637Z","shell.execute_reply.started":"2025-11-23T14:06:07.579133Z","shell.execute_reply":"2025-11-23T14:06:07.587676Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:06:11.553279Z","iopub.execute_input":"2025-11-23T14:06:11.553566Z","iopub.status.idle":"2025-11-23T14:06:11.5599Z","shell.execute_reply.started":"2025-11-23T14:06:11.553547Z","shell.execute_reply":"2025-11-23T14:06:11.558732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#dropping all categorical_left columns\ntest_df.drop(columns = categorical_left, inplace = True)\ntest_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:06:13.398774Z","iopub.execute_input":"2025-11-23T14:06:13.399121Z","iopub.status.idle":"2025-11-23T14:06:13.408182Z","shell.execute_reply.started":"2025-11-23T14:06:13.399093Z","shell.execute_reply":"2025-11-23T14:06:13.407062Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#using YearBuilt , GarageYrBlt , YrSold ,MoSold, YearRemodAdd\n#MoSold is month, no need to drop them as they tell which month , season has high/low price.\ntest_df['HouseAge'] = test_df['YrSold'] - test_df['YearBuilt']\ntest_df['GarageAge'] = test_df['YrSold'] - test_df['GarageYrBlt']\ntest_df['RemodAdd'] = test_df['YrSold'] - test_df['YearRemodAdd']\ntest_df.drop(columns = ['YrSold','YearBuilt','GarageYrBlt','YearRemodAdd'], inplace = True)\n#clipping negative values to 0\ntest_df[\"RemodAdd\"] = test_df[\"RemodAdd\"].clip(lower=0)\n\ntest_df[['HouseAge','GarageAge','RemodAdd']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:06:15.625134Z","iopub.execute_input":"2025-11-23T14:06:15.625424Z","iopub.status.idle":"2025-11-23T14:06:15.644963Z","shell.execute_reply.started":"2025-11-23T14:06:15.625405Z","shell.execute_reply":"2025-11-23T14:06:15.643654Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df[\"HouseAge\"] = test_df[\"HouseAge\"].clip(lower=0)\ntest_df[\"GarageAge\"] = test_df[\"GarageAge\"].clip(lower=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:06:17.781488Z","iopub.execute_input":"2025-11-23T14:06:17.781813Z","iopub.status.idle":"2025-11-23T14:06:17.79102Z","shell.execute_reply.started":"2025-11-23T14:06:17.781787Z","shell.execute_reply":"2025-11-23T14:06:17.78979Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#dropping similar features\ntest_df.drop(columns = similar_feats, inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:06:19.694985Z","iopub.execute_input":"2025-11-23T14:06:19.695366Z","iopub.status.idle":"2025-11-23T14:06:19.702843Z","shell.execute_reply.started":"2025-11-23T14:06:19.695339Z","shell.execute_reply":"2025-11-23T14:06:19.701841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features_requiring_normalization = list(set(features_requiring_normalization) - set(['SalePrice']))\ntest_df[features_requiring_normalization] = np.log1p(test_df[features_requiring_normalization])\ntest_df[features_requiring_normalization]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:06:22.179077Z","iopub.execute_input":"2025-11-23T14:06:22.179414Z","iopub.status.idle":"2025-11-23T14:06:22.213585Z","shell.execute_reply.started":"2025-11-23T14:06:22.179394Z","shell.execute_reply":"2025-11-23T14:06:22.212431Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#scaling is not applied on target feature and neither on categorical, since it alters the only thing we want to predict as it is.\ntest_df[features_requiring_scaling] = sc.transform(test_df[features_requiring_scaling])\ntest_df[features_requiring_scaling]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:06:24.516669Z","iopub.execute_input":"2025-11-23T14:06:24.517044Z","iopub.status.idle":"2025-11-23T14:06:24.550964Z","shell.execute_reply.started":"2025-11-23T14:06:24.51702Z","shell.execute_reply":"2025-11-23T14:06:24.550144Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Id = test_df['Id']\nfeats = test_df.drop(columns = ['Id', 'SalePrice'])\nprint(feats.shape, Id.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:06:29.1504Z","iopub.execute_input":"2025-11-23T14:06:29.150724Z","iopub.status.idle":"2025-11-23T14:06:29.16043Z","shell.execute_reply.started":"2025-11-23T14:06:29.150682Z","shell.execute_reply":"2025-11-23T14:06:29.159449Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#order also might be different, such as Train is: A,B,C,D\n#while test is D,A,C,B\n#we need to align them\nX2, feats2 = X.align(feats, join=\"left\", axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:06:33.108857Z","iopub.execute_input":"2025-11-23T14:06:33.109257Z","iopub.status.idle":"2025-11-23T14:06:33.119949Z","shell.execute_reply.started":"2025-11-23T14:06:33.109233Z","shell.execute_reply":"2025-11-23T14:06:33.118859Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feats2.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:06:35.079449Z","iopub.execute_input":"2025-11-23T14:06:35.079787Z","iopub.status.idle":"2025-11-23T14:06:35.087025Z","shell.execute_reply.started":"2025-11-23T14:06:35.07976Z","shell.execute_reply":"2025-11-23T14:06:35.085767Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub_predict = ridge_model.predict(feats2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:06:41.389241Z","iopub.execute_input":"2025-11-23T14:06:41.389539Z","iopub.status.idle":"2025-11-23T14:06:41.401721Z","shell.execute_reply.started":"2025-11-23T14:06:41.389515Z","shell.execute_reply":"2025-11-23T14:06:41.400485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sub_predict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:06:48.591636Z","iopub.execute_input":"2025-11-23T14:06:48.591987Z","iopub.status.idle":"2025-11-23T14:06:48.5988Z","shell.execute_reply.started":"2025-11-23T14:06:48.591962Z","shell.execute_reply":"2025-11-23T14:06:48.597934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = pd.DataFrame({\n    \"Id\":Id,\n    \"SalePrice\":np.expm1(sub_predict)\n})\n\nsubmission.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:07:19.330118Z","iopub.execute_input":"2025-11-23T14:07:19.330477Z","iopub.status.idle":"2025-11-23T14:07:19.340947Z","shell.execute_reply.started":"2025-11-23T14:07:19.330452Z","shell.execute_reply":"2025-11-23T14:07:19.339879Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T14:07:23.669247Z","iopub.execute_input":"2025-11-23T14:07:23.669578Z","iopub.status.idle":"2025-11-23T14:07:23.685383Z","shell.execute_reply.started":"2025-11-23T14:07:23.669554Z","shell.execute_reply":"2025-11-23T14:07:23.684114Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}