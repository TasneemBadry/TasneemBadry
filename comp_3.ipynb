{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNebrR++RzPjcm3Qk+4VVa8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TasneemBadry/TasneemBadry/blob/main/comp_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data**"
      ],
      "metadata": {
        "id": "g50PIhVsm0MN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the following steps to upload data from kaggle directly"
      ],
      "metadata": {
        "id": "-RH4nvyqN4mC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gC-uVEej8yfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "410d352a-3c11-496c-fc0b-df9977bc2f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kaggle\n",
            "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▋                          | 10 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 58 kB 3.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73051 sha256=0adc7ddc53c078feb48de583a49fedac0dffec017dea251db3d1954cc1899c6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "!mkdir ~/.kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "rIpJKQRbAfmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download and process the data from kaggle\n",
        "!kaggle competitions download -c cisc-873-dm-f22-a2\n",
        "!unzip \"/content/cisc-873-dm-f22-a2.zip\" # extracting files\n",
        "#load data on colab and unzip it"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2SUInnRAfqN",
        "outputId": "e0cc0b16-ede7-417e-eb54-10c51767eb49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading cisc-873-dm-f22-a2.zip to /content\n",
            "\r  0% 0.00/1.46M [00:00<?, ?B/s]\n",
            "\r100% 1.46M/1.46M [00:00<00:00, 52.3MB/s]\n",
            "Archive:  /content/cisc-873-dm-f22-a2.zip\n",
            "  inflating: Speed Dating Data Description.pdf  \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now we just start the model\n",
        "#first step is libraries\n",
        "import pandas as pd          #pandas help to read data files\n",
        "import numpy as np           #\n"
      ],
      "metadata": {
        "id": "ViBns01sCSWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f=pd.read_csv('/content/train.csv') #read data by pandas\n",
        "f"
      ],
      "metadata": {
        "id": "q2W4nWlrCSnl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "e98edd14-e5ac-48fc-916a-268bc007aa0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5989d0aa-e394-4cda-839d-d21727b68002\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>idg</th>\n",
              "      <th>condtn</th>\n",
              "      <th>wave</th>\n",
              "      <th>round</th>\n",
              "      <th>position</th>\n",
              "      <th>positin1</th>\n",
              "      <th>order</th>\n",
              "      <th>partner</th>\n",
              "      <th>pid</th>\n",
              "      <th>...</th>\n",
              "      <th>sinc3_3</th>\n",
              "      <th>intel3_3</th>\n",
              "      <th>fun3_3</th>\n",
              "      <th>amb3_3</th>\n",
              "      <th>attr5_3</th>\n",
              "      <th>sinc5_3</th>\n",
              "      <th>intel5_3</th>\n",
              "      <th>fun5_3</th>\n",
              "      <th>amb5_3</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>14</td>\n",
              "      <td>12</td>\n",
              "      <td>372.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>63.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>331.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>18</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>200.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>14</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>6.0</td>\n",
              "      <td>20</td>\n",
              "      <td>17</td>\n",
              "      <td>357.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5904</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>214.0</td>\n",
              "      <td>...</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5905</th>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>19</td>\n",
              "      <td>15.0</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>199.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5906</th>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>290.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5907</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>16</td>\n",
              "      <td>6</td>\n",
              "      <td>14.0</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>151.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5908</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>21</td>\n",
              "      <td>22</td>\n",
              "      <td>7</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>542.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8149</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5909 rows × 192 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5989d0aa-e394-4cda-839d-d21727b68002')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5989d0aa-e394-4cda-839d-d21727b68002 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5989d0aa-e394-4cda-839d-d21727b68002');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
              "0          0    3       2    14     18         2       2.0     14       12   \n",
              "1          1   14       1     3     10         2       NaN      8        8   \n",
              "2          1   14       1    13     10         8       8.0     10       10   \n",
              "3          1   38       2     9     20        18      13.0      6        7   \n",
              "4          1   24       2    14     20         6       6.0     20       17   \n",
              "...      ...  ...     ...   ...    ...       ...       ...    ...      ...   \n",
              "5904       0    1       2     9     20         2       2.0     18        1   \n",
              "5905       1   24       2     9     20        19      15.0      5        6   \n",
              "5906       0   13       2    11     21         5       5.0      3       18   \n",
              "5907       1   10       2     7     16         6      14.0      9       10   \n",
              "5908       0    7       2    21     22         7       7.0      2       12   \n",
              "\n",
              "        pid  ...  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  \\\n",
              "0     372.0  ...      NaN       NaN     NaN     NaN      NaN      NaN   \n",
              "1      63.0  ...      8.0       8.0     7.0     8.0      NaN      NaN   \n",
              "2     331.0  ...      NaN       NaN     NaN     NaN      NaN      NaN   \n",
              "3     200.0  ...      9.0       8.0     8.0     6.0      NaN      NaN   \n",
              "4     357.0  ...      NaN       NaN     NaN     NaN      NaN      NaN   \n",
              "...     ...  ...      ...       ...     ...     ...      ...      ...   \n",
              "5904  214.0  ...     12.0      12.0     9.0    12.0      NaN      NaN   \n",
              "5905  199.0  ...      NaN       NaN     NaN     NaN      NaN      NaN   \n",
              "5906  290.0  ...      NaN       NaN     NaN     NaN      NaN      NaN   \n",
              "5907  151.0  ...      NaN       NaN     NaN     NaN      NaN      NaN   \n",
              "5908  542.0  ...      NaN       NaN     NaN     NaN      NaN      NaN   \n",
              "\n",
              "      intel5_3  fun5_3  amb5_3    id  \n",
              "0          NaN     NaN     NaN  2583  \n",
              "1          NaN     NaN     NaN  6830  \n",
              "2          NaN     NaN     NaN  4840  \n",
              "3          NaN     NaN     NaN  5508  \n",
              "4          NaN     NaN     NaN  4828  \n",
              "...        ...     ...     ...   ...  \n",
              "5904       NaN     NaN     NaN  3390  \n",
              "5905       NaN     NaN     NaN  4130  \n",
              "5906       NaN     NaN     NaN  1178  \n",
              "5907       NaN     NaN     NaN  5016  \n",
              "5908       NaN     NaN     NaN  8149  \n",
              "\n",
              "[5909 rows x 192 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f.info(verbose=True)   #to know data types and its numbers of each type"
      ],
      "metadata": {
        "id": "DB85nYBNCSrB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa8af26-7b01-47e8-8af0-1ab7015aa7e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5909 entries, 0 to 5908\n",
            "Data columns (total 192 columns):\n",
            " #    Column    Dtype  \n",
            "---   ------    -----  \n",
            " 0    gender    int64  \n",
            " 1    idg       int64  \n",
            " 2    condtn    int64  \n",
            " 3    wave      int64  \n",
            " 4    round     int64  \n",
            " 5    position  int64  \n",
            " 6    positin1  float64\n",
            " 7    order     int64  \n",
            " 8    partner   int64  \n",
            " 9    pid       float64\n",
            " 10   match     int64  \n",
            " 11   int_corr  float64\n",
            " 12   samerace  int64  \n",
            " 13   age_o     float64\n",
            " 14   race_o    float64\n",
            " 15   pf_o_att  float64\n",
            " 16   pf_o_sin  float64\n",
            " 17   pf_o_int  float64\n",
            " 18   pf_o_fun  float64\n",
            " 19   pf_o_amb  float64\n",
            " 20   pf_o_sha  float64\n",
            " 21   attr_o    float64\n",
            " 22   sinc_o    float64\n",
            " 23   intel_o   float64\n",
            " 24   fun_o     float64\n",
            " 25   amb_o     float64\n",
            " 26   shar_o    float64\n",
            " 27   like_o    float64\n",
            " 28   prob_o    float64\n",
            " 29   met_o     float64\n",
            " 30   age       float64\n",
            " 31   field     object \n",
            " 32   field_cd  float64\n",
            " 33   undergra  object \n",
            " 34   mn_sat    object \n",
            " 35   tuition   object \n",
            " 36   race      float64\n",
            " 37   imprace   float64\n",
            " 38   imprelig  float64\n",
            " 39   from      object \n",
            " 40   zipcode   object \n",
            " 41   income    object \n",
            " 42   goal      float64\n",
            " 43   date      float64\n",
            " 44   go_out    float64\n",
            " 45   career    object \n",
            " 46   career_c  float64\n",
            " 47   sports    float64\n",
            " 48   tvsports  float64\n",
            " 49   exercise  float64\n",
            " 50   dining    float64\n",
            " 51   museums   float64\n",
            " 52   art       float64\n",
            " 53   hiking    float64\n",
            " 54   gaming    float64\n",
            " 55   clubbing  float64\n",
            " 56   reading   float64\n",
            " 57   tv        float64\n",
            " 58   theater   float64\n",
            " 59   movies    float64\n",
            " 60   concerts  float64\n",
            " 61   music     float64\n",
            " 62   shopping  float64\n",
            " 63   yoga      float64\n",
            " 64   exphappy  float64\n",
            " 65   expnum    float64\n",
            " 66   attr1_1   float64\n",
            " 67   sinc1_1   float64\n",
            " 68   intel1_1  float64\n",
            " 69   fun1_1    float64\n",
            " 70   amb1_1    float64\n",
            " 71   shar1_1   float64\n",
            " 72   attr4_1   float64\n",
            " 73   sinc4_1   float64\n",
            " 74   intel4_1  float64\n",
            " 75   fun4_1    float64\n",
            " 76   amb4_1    float64\n",
            " 77   shar4_1   float64\n",
            " 78   attr2_1   float64\n",
            " 79   sinc2_1   float64\n",
            " 80   intel2_1  float64\n",
            " 81   fun2_1    float64\n",
            " 82   amb2_1    float64\n",
            " 83   shar2_1   float64\n",
            " 84   attr3_1   float64\n",
            " 85   sinc3_1   float64\n",
            " 86   fun3_1    float64\n",
            " 87   intel3_1  float64\n",
            " 88   amb3_1    float64\n",
            " 89   attr5_1   float64\n",
            " 90   sinc5_1   float64\n",
            " 91   intel5_1  float64\n",
            " 92   fun5_1    float64\n",
            " 93   amb5_1    float64\n",
            " 94   attr      float64\n",
            " 95   sinc      float64\n",
            " 96   intel     float64\n",
            " 97   fun       float64\n",
            " 98   amb       float64\n",
            " 99   shar      float64\n",
            " 100  like      float64\n",
            " 101  prob      float64\n",
            " 102  met       float64\n",
            " 103  match_es  float64\n",
            " 104  attr1_s   float64\n",
            " 105  sinc1_s   float64\n",
            " 106  intel1_s  float64\n",
            " 107  fun1_s    float64\n",
            " 108  amb1_s    float64\n",
            " 109  shar1_s   float64\n",
            " 110  attr3_s   float64\n",
            " 111  sinc3_s   float64\n",
            " 112  intel3_s  float64\n",
            " 113  fun3_s    float64\n",
            " 114  amb3_s    float64\n",
            " 115  satis_2   float64\n",
            " 116  length    float64\n",
            " 117  numdat_2  float64\n",
            " 118  attr7_2   float64\n",
            " 119  sinc7_2   float64\n",
            " 120  intel7_2  float64\n",
            " 121  fun7_2    float64\n",
            " 122  amb7_2    float64\n",
            " 123  shar7_2   float64\n",
            " 124  attr1_2   float64\n",
            " 125  sinc1_2   float64\n",
            " 126  intel1_2  float64\n",
            " 127  fun1_2    float64\n",
            " 128  amb1_2    float64\n",
            " 129  shar1_2   float64\n",
            " 130  attr4_2   float64\n",
            " 131  sinc4_2   float64\n",
            " 132  intel4_2  float64\n",
            " 133  fun4_2    float64\n",
            " 134  amb4_2    float64\n",
            " 135  shar4_2   float64\n",
            " 136  attr2_2   float64\n",
            " 137  sinc2_2   float64\n",
            " 138  intel2_2  float64\n",
            " 139  fun2_2    float64\n",
            " 140  amb2_2    float64\n",
            " 141  shar2_2   float64\n",
            " 142  attr3_2   float64\n",
            " 143  sinc3_2   float64\n",
            " 144  intel3_2  float64\n",
            " 145  fun3_2    float64\n",
            " 146  amb3_2    float64\n",
            " 147  attr5_2   float64\n",
            " 148  sinc5_2   float64\n",
            " 149  intel5_2  float64\n",
            " 150  fun5_2    float64\n",
            " 151  amb5_2    float64\n",
            " 152  you_call  float64\n",
            " 153  them_cal  float64\n",
            " 154  date_3    float64\n",
            " 155  numdat_3  float64\n",
            " 156  num_in_3  float64\n",
            " 157  attr1_3   float64\n",
            " 158  sinc1_3   float64\n",
            " 159  intel1_3  float64\n",
            " 160  fun1_3    float64\n",
            " 161  amb1_3    float64\n",
            " 162  shar1_3   float64\n",
            " 163  attr7_3   float64\n",
            " 164  sinc7_3   float64\n",
            " 165  intel7_3  float64\n",
            " 166  fun7_3    float64\n",
            " 167  amb7_3    float64\n",
            " 168  shar7_3   float64\n",
            " 169  attr4_3   float64\n",
            " 170  sinc4_3   float64\n",
            " 171  intel4_3  float64\n",
            " 172  fun4_3    float64\n",
            " 173  amb4_3    float64\n",
            " 174  shar4_3   float64\n",
            " 175  attr2_3   float64\n",
            " 176  sinc2_3   float64\n",
            " 177  intel2_3  float64\n",
            " 178  fun2_3    float64\n",
            " 179  amb2_3    float64\n",
            " 180  shar2_3   float64\n",
            " 181  attr3_3   float64\n",
            " 182  sinc3_3   float64\n",
            " 183  intel3_3  float64\n",
            " 184  fun3_3    float64\n",
            " 185  amb3_3    float64\n",
            " 186  attr5_3   float64\n",
            " 187  sinc5_3   float64\n",
            " 188  intel5_3  float64\n",
            " 189  fun5_3    float64\n",
            " 190  amb5_3    float64\n",
            " 191  id        int64  \n",
            "dtypes: float64(173), int64(11), object(8)\n",
            "memory usage: 8.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f.isnull().sum()  #to know each column if contain nanvalues or no and their number in each column"
      ],
      "metadata": {
        "id": "st1tUxH-AvVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1fb72a6-43af-4962-d25c-63f8496900c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gender         0\n",
              "idg            0\n",
              "condtn         0\n",
              "wave           0\n",
              "round          0\n",
              "            ... \n",
              "sinc5_3     4496\n",
              "intel5_3    4496\n",
              "fun5_3      4496\n",
              "amb5_3      4496\n",
              "id             0\n",
              "Length: 192, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t=f.drop(columns=['id'])    #drop it because it does not affect in data"
      ],
      "metadata": {
        "id": "QhGCvaTMV4eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now we determine inputs (X) and outputs (Y) from columns of data\n",
        "X=t.iloc[:,t.columns!='match']\n",
        "Y=t.match"
      ],
      "metadata": {
        "id": "WIwQFaR-c_3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#and splitting it to train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "kp3Cx99NdBor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Full PipLine**"
      ],
      "metadata": {
        "id": "Hz-p2GSq4Be9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we need to select each column containing any data type\n",
        "features_numeric = list(X_train.select_dtypes(include=['float64', 'int64']))  #to select columns which contain data types numeric (float and integer)\n",
        "\n",
        "features_categorical = list(X_train.select_dtypes(include=['category']))  #to select columns which contain data type text (category)\n",
        "\n",
        "print('numeric features:', features_numeric)\n",
        "print('categorical features:', features_categorical)\n",
        "#printing them to make sure"
      ],
      "metadata": {
        "id": "BDLtyXWoc2bG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a57ebc20-3057-4057-e718-193f9c6c5dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numeric features: ['gender', 'idg', 'condtn', 'wave', 'round', 'position', 'positin1', 'order', 'partner', 'pid', 'int_corr', 'samerace', 'age_o', 'race_o', 'pf_o_att', 'pf_o_sin', 'pf_o_int', 'pf_o_fun', 'pf_o_amb', 'pf_o_sha', 'attr_o', 'sinc_o', 'intel_o', 'fun_o', 'amb_o', 'shar_o', 'like_o', 'prob_o', 'met_o', 'age', 'field_cd', 'race', 'imprace', 'imprelig', 'goal', 'date', 'go_out', 'career_c', 'sports', 'tvsports', 'exercise', 'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga', 'exphappy', 'expnum', 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1', 'attr4_1', 'sinc4_1', 'intel4_1', 'fun4_1', 'amb4_1', 'shar4_1', 'attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1', 'attr3_1', 'sinc3_1', 'fun3_1', 'intel3_1', 'amb3_1', 'attr5_1', 'sinc5_1', 'intel5_1', 'fun5_1', 'amb5_1', 'attr', 'sinc', 'intel', 'fun', 'amb', 'shar', 'like', 'prob', 'met', 'match_es', 'attr1_s', 'sinc1_s', 'intel1_s', 'fun1_s', 'amb1_s', 'shar1_s', 'attr3_s', 'sinc3_s', 'intel3_s', 'fun3_s', 'amb3_s', 'satis_2', 'length', 'numdat_2', 'attr7_2', 'sinc7_2', 'intel7_2', 'fun7_2', 'amb7_2', 'shar7_2', 'attr1_2', 'sinc1_2', 'intel1_2', 'fun1_2', 'amb1_2', 'shar1_2', 'attr4_2', 'sinc4_2', 'intel4_2', 'fun4_2', 'amb4_2', 'shar4_2', 'attr2_2', 'sinc2_2', 'intel2_2', 'fun2_2', 'amb2_2', 'shar2_2', 'attr3_2', 'sinc3_2', 'intel3_2', 'fun3_2', 'amb3_2', 'attr5_2', 'sinc5_2', 'intel5_2', 'fun5_2', 'amb5_2', 'you_call', 'them_cal', 'date_3', 'numdat_3', 'num_in_3', 'attr1_3', 'sinc1_3', 'intel1_3', 'fun1_3', 'amb1_3', 'shar1_3', 'attr7_3', 'sinc7_3', 'intel7_3', 'fun7_3', 'amb7_3', 'shar7_3', 'attr4_3', 'sinc4_3', 'intel4_3', 'fun4_3', 'amb4_3', 'shar4_3', 'attr2_3', 'sinc2_3', 'intel2_3', 'fun2_3', 'amb2_3', 'shar2_3', 'attr3_3', 'sinc3_3', 'intel3_3', 'fun3_3', 'amb3_3', 'attr5_3', 'sinc5_3', 'intel5_3', 'fun5_3', 'amb5_3']\n",
            "categorical features: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's start preprocessing for data\n",
        "#we use fullpipline because I can do all steps of preprocessing to all columns in one step to numeric and categorical data\n",
        "from sklearn.compose import ColumnTransformer   #to transform old data to new data after preprocessing and apply it\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer    #kind of imputer to fill nanvalues\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder   #kind of encoding to convert text data to category to make easier tunning hyperparameters\n",
        "from sklearn.ensemble import RandomForestClassifier  # in the first try I apply this classifier\n",
        "from sklearn.model_selection import GridSearchCV   # with grid search\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "\n",
        "transformer_numeric = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', SimpleImputer()),   #fill nanvalues to columns contain numeric data\n",
        "        ('scaler', StandardScaler())]   #and make scalling to data\n",
        ")\n",
        "#put this transform in pipline\n",
        "\n",
        "transformer_categorical = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', SimpleImputer(strategy='constant')),   #fill nanvalues to columns contain text data\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))    # and convert it to category by one hot encoding\n",
        "    ]\n",
        ")\n",
        "#put this transform in pipline\n",
        "\n",
        "#apply this transformers on specified data in features_numeric and features_categorical\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', transformer_numeric, features_numeric),\n",
        "        ('cat', transformer_categorical, features_categorical)\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "#and put it all steps with the selected classifier to apply them\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('my_classifier',\n",
        "           RandomForestClassifier(),\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "full_pipline   #just to show it"
      ],
      "metadata": {
        "id": "ysonmhcIEzsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a02f6c75-fef0-4241-9dc9-bf9001b046ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('num',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  ('scaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  ['gender', 'idg', 'condtn',\n",
              "                                                   'wave', 'round', 'position',\n",
              "                                                   'positin1', 'order',\n",
              "                                                   'partner', 'pid', 'int_corr',\n",
              "                                                   'samerace', 'age_o',\n",
              "                                                   'race_o', 'pf_o_att',\n",
              "                                                   'pf_o_sin', 'pf_o_int',\n",
              "                                                   'pf_o_fun', 'pf_o_amb',\n",
              "                                                   'pf_o_sha', 'attr_o',\n",
              "                                                   'sinc_o', 'intel_o', 'fun_o',\n",
              "                                                   'amb_o', 'shar_o', 'like_o',\n",
              "                                                   'prob_o', 'met_o', 'age', ...]),\n",
              "                                                 ('cat',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer(strategy='constant')),\n",
              "                                                                  ('onehot',\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                                  [])])),\n",
              "                ('my_classifier', RandomForestClassifier())])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#apply full pipline on train data\n",
        "#and predict it on test data\n",
        "full_pipline = full_pipline.fit(X_train, y_train)\n",
        "full_pipline.predict(X_test)"
      ],
      "metadata": {
        "id": "xSsqgyVKdYwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff11f2b8-4699-4ce8-9f26-008098294c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Grid Search**"
      ],
      "metadata": {
        "id": "xzKfuCDE4_jU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#grid search with this hypapermeter give best accuracy on kaggle but if we change 'my_classifier__max_depth' to 'my_classifier__min_sample_leaf' this give a low accuracy\n",
        "param_grid = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    'my_classifier__n_estimators': [20, 30, 40],\n",
        "    'my_classifier__max_depth':[10, 20, 30]\n",
        "}\n",
        "\n",
        "#we also put pipline (all preprocessing) with tunning\n",
        "grid_search = GridSearchCV(\n",
        "    full_pipline, param_grid, cv=2, verbose=1, n_jobs=2,\n",
        "    scoring='roc_auc')\n",
        "#and fit grid search on train data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(grid_search.best_score_))\n",
        "print('best score {}'.format(grid_search.best_params_))"
      ],
      "metadata": {
        "id": "c5Ins_l5du2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bc0d218-72e1-4951-98c8-5102498afee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n",
            "best score 0.8291576400379542\n",
            "best score {'my_classifier__max_depth': 10, 'my_classifier__n_estimators': 40, 'preprocessor__num__imputer__strategy': 'mean'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read test data\n",
        "df=pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "c_OJFE9yeNfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#and drop id column from it like I do on train data\n",
        "d=df.drop(columns=['id'])"
      ],
      "metadata": {
        "id": "A2sPD1_nk3BN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.predict(d)  #apply tunning grid search on test data"
      ],
      "metadata": {
        "id": "pYW8UiUTdz9l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c39b98a-e8a8-4c13-e7af-0b47dad31d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#and submission the result in kaggle to calculate accuracy score\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = df['id']\n",
        "\n",
        "submission['match'] = grid_search.predict_proba(d)[:,1]"
      ],
      "metadata": {
        "id": "Pml3y5FtfZgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('Grid Search.csv', index=False)   #print submission on excel sheet"
      ],
      "metadata": {
        "id": "p-_EmwasUBE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.86525   \n",
        "this the first accuracy and the best"
      ],
      "metadata": {
        "id": "KzFc-l0aX7ku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#now we change the type of classifier to logistic regression and apply it on pipline\n",
        "from sklearn.linear_model import LogisticRegression    #library for logistic classifier\n",
        "\n",
        "log_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('my_classifier',\n",
        "           LogisticRegression(solver='liblinear'),\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "log_pipline     #print it just to make sure"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZMzH6WNGiiW",
        "outputId": "8c460a74-8ae9-4058-9389-fc7c9deb77d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('num',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  ('scaler',\n",
              "                                                                   StandardScaler())]),\n",
              "                                                  ['gender', 'idg', 'condtn',\n",
              "                                                   'wave', 'round', 'position',\n",
              "                                                   'positin1', 'order',\n",
              "                                                   'partner', 'pid', 'int_corr',\n",
              "                                                   'samerace', 'age_o',\n",
              "                                                   'race_o', 'pf_o_att',\n",
              "                                                   'pf_o_sin', 'pf_o_int',\n",
              "                                                   'pf_o_fun', 'pf_o_amb',\n",
              "                                                   'pf_o_sha', 'attr_o',\n",
              "                                                   'sinc_o', 'intel_o', 'fun_o',\n",
              "                                                   'amb_o', 'shar_o', 'like_o',\n",
              "                                                   'prob_o', 'met_o', 'age', ...]),\n",
              "                                                 ('cat',\n",
              "                                                  Pipeline(steps=[('imputer',\n",
              "                                                                   SimpleImputer(strategy='constant')),\n",
              "                                                                  ('onehot',\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                                  [])])),\n",
              "                ('my_classifier', LogisticRegression(solver='liblinear'))])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#apply logistic pipline on train data\n",
        "#and predict on input test data\n",
        "log_pipline = log_pipline.fit(X_train, y_train)\n",
        "log_pipline.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO_btEb_Gipu",
        "outputId": "a2907892-cdbf-4e12-ddf0-bb387731dada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now we need to apply new pipline with logistic regression in grid search after change hyperparameters to \"my_classifier__penalty\"\n",
        "log_param_grid = {\"my_classifier__C\":np.logspace(-3,3,7),\"my_classifier__penalty\":[\"l1\",\"l2\"]}\n",
        "log_grid_search = GridSearchCV(\n",
        "    log_pipline, log_param_grid, cv=2, verbose=1, n_jobs=2,\n",
        "    scoring='roc_auc')\n",
        "#fit grid search with logistic on train data\n",
        "log_grid_search.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(log_grid_search.best_score_))\n",
        "print('best score {}'.format(log_grid_search.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyaWsdtmGixi",
        "outputId": "e164209a-4bcc-451c-bbc6-f6c7182f2b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 14 candidates, totalling 28 fits\n",
            "best score 0.8576768821260037\n",
            "best score {'my_classifier__C': 0.1, 'my_classifier__penalty': 'l1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predict this on test data\n",
        "log_grid_search.predict(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW6xmKuFHIfx",
        "outputId": "778387d1-e890-463b-ec5d-03fb1dd1d960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = df['id']\n",
        "\n",
        "submission['match'] = log_grid_search.predict_proba(d)[:,1]\n",
        "\n",
        "submission.to_csv('Grid Search logistic.csv', index=False)\n",
        "#this submission is the same best accuracy on kaggle so grid search with any classifier is the best"
      ],
      "metadata": {
        "id": "SzMfazJ8bVpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.86525 logistic  \n",
        "the second best accuracy\n"
      ],
      "metadata": {
        "id": "LXE4QBfjGhPr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Search**"
      ],
      "metadata": {
        "id": "AUKZdKe6QE16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#let's start random search with random forest classifier\n",
        "from sklearn.ensemble import RandomForestRegressor     #for random classifier\n",
        "from sklearn.model_selection import RandomizedSearchCV      #for random search\n",
        "random_search = RandomizedSearchCV(\n",
        "    full_pipline, param_grid, cv=5, verbose=1, n_jobs=2,\n",
        "    n_iter=10,\n",
        "    scoring='roc_auc')\n",
        "random_search.fit(X_train, y_train)\n",
        "print('best score {}'.format(random_search.best_score_))\n",
        "print('best score {}'.format(random_search.best_params_))"
      ],
      "metadata": {
        "id": "Qi2Uz-DzQKnW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a97cbc15-bd99-4819-f284-70957bfe6a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:296: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "best score 0.8409134516890576\n",
            "best score {'preprocessor__num__imputer__strategy': 'mean', 'my_classifier__n_estimators': 40, 'my_classifier__max_depth': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#and predict it on test data\n",
        "random_search.predict(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBGbxe65XOii",
        "outputId": "16aaab99-baf7-4dcc-cec3-12dce2c1e8e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#submit its result on kaggle to calculate accuracy\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = df['id']\n",
        "\n",
        "submission['match'] = random_search.predict_proba(d)[:,1]"
      ],
      "metadata": {
        "id": "Vfg4jN0XXcOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('Random Search.csv', index=False)"
      ],
      "metadata": {
        "id": "o4SFcKvEXf33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.85110  \n",
        "third accuracy, it is not better than grid search"
      ],
      "metadata": {
        "id": "Es3CSAdmi1BD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#random search with logistic regression classifier\n",
        "log_param_grid = {\"my_classifier__C\":np.logspace(-3,3,7),\"my_classifier__penalty\":[\"l1\",\"l2\"]}\n",
        "log_random_search = RandomizedSearchCV(\n",
        "    log_pipline, log_param_grid, cv=2, verbose=1, n_jobs=2,\n",
        "    scoring='roc_auc')\n",
        "\n",
        "log_random_search.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(log_random_search.best_score_))\n",
        "print('best score {}'.format(log_random_search.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg8eWItYk8sB",
        "outputId": "00dc98e2-0310-4f80-aa6a-e94c7d8e6361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
            "best score 0.8576841214649435\n",
            "best score {'my_classifier__penalty': 'l1', 'my_classifier__C': 0.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#and predict on test data\n",
        "log_random_search.predict(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oFco6EDlwsa",
        "outputId": "45a6c510-64cb-42d0-be99-95a452180f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#submit on kaggle to give accuracy\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = df['id']\n",
        "\n",
        "submission['match'] = log_random_search.predict_proba(d)[:,1]\n",
        "\n",
        "submission.to_csv('Random Search logistic.csv', index=False)\n",
        "#accuracy of random search with logistic regression is better than accuracy of random search with random forest classifier little bit"
      ],
      "metadata": {
        "id": "9HxsevXbl1-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.85471  \n",
        "forth result\n"
      ],
      "metadata": {
        "id": "hPv-q0QZmNU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bayesian Search**"
      ],
      "metadata": {
        "id": "kN2dG6JejDMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize  #install optimizer to apply bayesian search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gY4CxB5jdub",
        "outputId": "45962fb2-3ea6-4c20-aa9b-b1845f23b571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.1.0)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.21.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's start baysian search\n",
        "#first trial bayes search with SVM\n",
        "from skopt import BayesSearchCV    #to import bayes search\n",
        "from skopt.space import Real, Categorical, Integer   #libraries tune hyperparameter of svm\n",
        "from sklearn.svm import SVC   #import svm\n",
        "\n",
        "\n",
        "SVC_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('my_svc', SVC(class_weight='balanced',probability=True))\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "bayes_search = BayesSearchCV(\n",
        "    SVC_pipline,\n",
        "    {\n",
        "        'my_svc__C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
        "        'my_svc__gamma': Real(1e-6, 1e+1, prior='log-uniform'),\n",
        "        'my_svc__degree': Integer(1,8),\n",
        "        'my_svc__kernel': Categorical(['linear', 'poly', 'rbf']),\n",
        "    },\n",
        "    n_iter=3,\n",
        "    random_state=0,\n",
        "    verbose=1,\n",
        "    cv=7,\n",
        ")\n",
        "#apply bayes search with svm classifier on train data\n",
        "bayes_search.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(bayes_search.best_score_))\n",
        "print('best score {}'.format(bayes_search.best_params_))\n",
        "#printing best accuracy for this fitting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-OSWTdwjMxp",
        "outputId": "844aec3c-d8bc-4ff0-b3e9-88a84704aa02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 7 folds for each of 1 candidates, totalling 7 fits\n",
            "Fitting 7 folds for each of 1 candidates, totalling 7 fits\n",
            "Fitting 7 folds for each of 1 candidates, totalling 7 fits\n",
            "best score 0.8188976694527212\n",
            "best score OrderedDict([('my_svc__C', 0.0012602593949011189), ('my_svc__degree', 8), ('my_svc__gamma', 2.285959941576884), ('my_svc__kernel', 'poly')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#and apply it (predict) on test data\n",
        "bayes_search.predict(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32Zq6HFG1K1F",
        "outputId": "6053a264-f170-43d3-83a3-4450feb3006a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make submission to upload it on kaggle\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = df['id']\n",
        "\n",
        "submission['match'] = bayes_search.predict_proba(d)[:,1]"
      ],
      "metadata": {
        "id": "xkpQ_CrD1OTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('Bayes Search.csv', index=False)"
      ],
      "metadata": {
        "id": "kL8F0FfE1UEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.70310  \n",
        "fifth accuracy and this is the least accuracy the model calculate\n"
      ],
      "metadata": {
        "id": "Vqardqko1-Nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the last try to model\n",
        "#bayesian search with logistic regression\n",
        "log_bayes_search = BayesSearchCV(\n",
        "    log_pipline, log_param_grid,\n",
        "    n_iter=3,\n",
        "    random_state=0,\n",
        "    verbose=1,\n",
        "    cv=7,\n",
        ")\n",
        "#fit bayes search with logistic on train data\n",
        "log_bayes_search.fit(X_train, y_train)\n",
        "\n",
        "print('best score {}'.format(log_bayes_search.best_score_))\n",
        "print('best score {}'.format(log_bayes_search.best_params_))\n",
        "#printing best accuracy for this fitting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0qQYRIzeSvz",
        "outputId": "56e11577-a495-4c9f-aaaa-1eef02d50b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 7 folds for each of 1 candidates, totalling 7 fits\n",
            "Fitting 7 folds for each of 1 candidates, totalling 7 fits\n",
            "Fitting 7 folds for each of 1 candidates, totalling 7 fits\n",
            "best score 0.8585527109308341\n",
            "best score OrderedDict([('my_classifier__C', 1.0), ('my_classifier__penalty', 'l1')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#and apply it (predict) on test data\n",
        "log_bayes_search.predict(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYaOIFjOexMM",
        "outputId": "9c49c537-9416-46dd-b215-a38ef1a28fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make submission to upload it on kaggle\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = df['id']\n",
        "\n",
        "submission['match'] = log_bayes_search.predict_proba(d)[:,1]"
      ],
      "metadata": {
        "id": "PHfoIRHbe6ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('Bayes Search Logistic.csv', index=False)   #submit it to excel sheet"
      ],
      "metadata": {
        "id": "PN7QLTq2e_3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Score: 0.85775  \n",
        "sixth and last accuracy for the model"
      ],
      "metadata": {
        "id": "IUcyFztIfSJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Questions**"
      ],
      "metadata": {
        "id": "d1b13xPBFqfA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A1:**   \n",
        "Linear Regression is a machine learning algorithm based on supervised regression algorithm. Regression models a target prediction value based on independent variables. It is mostly used for finding out the relationship between variables and forecasting. Different regression models differ based on – the kind of relationship between the dependent and independent variables, they are considering and the number of independent variables being used.  \n",
        "Logistic regression is basically a supervised classification algorithm. In a classification problem, the target variable(or output), y, can take only discrete values for a given set of features(or inputs), X.\n",
        "\n"
      ],
      "metadata": {
        "id": "UKUSXcNzFyc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A2:**  \n",
        "Decision Tree : Decision tree is the most powerful and popular tool for classification and prediction. A Decision tree is a flowchart like tree structure, where each internal node denotes a test on an attribute, each branch represents an outcome of the test, and each leaf node (terminal node) holds a class label.   \n",
        "Decision Tree Regression:\n",
        "Decision tree regression observes features of an object and trains a model in the structure of a tree to predict data in the future to produce meaningful continuous output. Continuous output means that the output/result is not discrete, i.e., it is not represented just by a discrete, known set of numbers or values.  \n",
        "**Differences:**  \n",
        "\n",
        "\n",
        "*  Logistics Regression (LR) and Decision Tree (DT) both solve the Classification Problem, and both can be interpreted easily; however, both have pros and cons. Based on the nature of your data choose the appropriate algorithm.\n",
        "*   Logistic Regression assumes that the data is linearly (or curvy linearly) separable in space, and Decision Trees are non-linear classifiers; they do not require data to be linearly separable.\n",
        "\n",
        "\n",
        "*  Categorical data works well with Decision Trees, while continuous data work well with Logistic Regression.\n",
        "\n",
        "If your data is categorical, then Logistic Regression cannot handle pure categorical data (string format). Rather, you need to convert it into numerical data.\n",
        "*   Decision Trees handle skewed classes nicely if we let it grow fully.\n",
        "\n",
        "Logistic Regression does not handle skewed classes well. So, in this case, either increase the weight to the minority class or balance the class.  \n",
        "\n",
        "\n",
        "*   Logistic Regression does not handle missing values; we need to impute those values by mean, mode, and median.\n",
        "\n",
        "If there are many missing values, then imputing those may not be a good idea, since we are changing the distribution of data by imputing mean everywhere.\n",
        "\n",
        "Decision Trees works with missing values.\n",
        "*   Logistic regression will push the decision boundary towards the outlier.\n",
        "\n",
        "While a Decision Tree, at the initial stage, won't be affected by an outlier, since an impure leaf will contain nine +ve and one –ve outlier. The label for the leaf will be +ve, since the majority are positive.\n",
        "\n",
        "However, if we let the Decision Tree grow fully, the signal will mote to one side, while the outlier will be moved to the other — there will be one leaf for each outlier.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hdpp-K2MMKzs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A3:**  \n",
        "\n",
        "1.   Grid search:  \n",
        "•Try out every combination of the parameters  \n",
        "•Computationally expensive  \n",
        "•Global optimal (within the given range)  \n",
        "•Sklearn: model_selection.GridSearchCV\n",
        "2.   Random search:  \n",
        "•Try out a random subset   \n",
        "•`good enough`  \n",
        "•Local optimal (within the given range)  \n",
        "•Efficient (less trials)  \n",
        "•Sklearn: model_selection.RandomizedSearchCV\n",
        "\n"
      ],
      "metadata": {
        "id": "ETjmWeifMK57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A4:**   \n",
        "1.   Bayesian Optimization:  \n",
        "•As an optimization problem  \n",
        "•Trial -> estimated error -> Bayesian model estimates the next\n",
        "parameter to try -> trial -> repeat..    \n",
        "•pip install bayesian-optimization\n",
        "2.   Random search:  \n",
        "•Try out a random subset   \n",
        "•`good enough`  \n",
        "•Local optimal (within the given range)  \n",
        "•Efficient (less trials)  \n",
        "•Sklearn: model_selection.RandomizedSearchCV"
      ],
      "metadata": {
        "id": "pin_BrQ1MLBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**the ideal solutions:**  \n",
        "grid search with logistic regression or random forest classifiers   \n"
      ],
      "metadata": {
        "id": "Ykv5MXdAN9sU"
      }
    }
  ]
}